{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Getrude Gichuhi\n",
    "\n",
    "ID No: 106218\n",
    "\n",
    "Course Code: DSA 8501\n",
    "\n",
    "Course Name: PREDICTIVE AND OPTIMIZATION ANALYTICS\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Question One "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the DSA 8502 coursework and its application in solving data problems: \n",
    "Answer the following questions about sampling:\n",
    "\n",
    "a) List and briefly describe 2 sampling methods that can be used to overcome poor performance from a classification algorithm due to an unbalanced data set. (2 points)\n",
    "\n",
    "i. Random Oversampling: This method involves replicating the samples from the minority group to balance the class distribution. \n",
    " \n",
    "ii. Randome Undersampling: This method involves randomly removingg samples from the majority class to balance the class distribution.  \n",
    "\n",
    "b) For each of the sampling methods listed in your answer to part (a), briefly describe a drawback of each method (2 points)\n",
    "\n",
    "1. Oversampling could lead to overfitting\n",
    "2. Undersmpling can lead to too much information being removed, which means loss of important data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of supervised and unsupervised learning:\n",
    "\n",
    "a) Briefly describe two differences between unsupervised and supervised learning (4 points)\n",
    "i. In supervised learning the data is labeled, with an output of known variables, on the other hand in Unsupervised learning the data is not labeled, and the algorithm requires to finding patterns and relationships within the data. \n",
    "\n",
    "ii. In supervised learning, there is a clear relationship between the input features and the output variables, meaning the model is learnt. In unsupevised Learning, there is no clear relationship between the input features and the output variables, with the model finding a relationship and pattern on it's own. \n",
    "\n",
    "b) Give two situations in which unsupervised learning would be preferred to supervised learning (2 points)\n",
    "\n",
    "i. Anomaly Detection: When identifying data points that are different from the majority which tend to indicate unusual occurence or events. Then using Unsupervised learning is better than supervised. \n",
    "\n",
    "ii. Dimensionality Reduction: In case of the goal is to reduce the number of features in a dataset while rretaining the most important information, then using unsupervised learning is preferred, barely since it can identify the relevant features without labels. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give two situations in which supervised learning would be preferred to unsupervised learning (2 points)\n",
    "\n",
    "i. Fraud Detection: Supervised learning could be used to identify fraudulent transactions based on past exampls of fraud. Letting the model learn on the input features and the output features if they are fraudulent or not. \n",
    "\n",
    "ii. Reccomender Systems: The main goal is recommend items to users based on their past behaviors and preference. Since supervised uses labeled data, the model can be used to learn the relationship between the input and the output to recommend items to users. A casing point is the Netflix recommendation based on past movies genre watched. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Fold Cross Validation\n",
    "Consider one of the validation approaches for measuring test errors in model validation. Briefly describe one advantage and one disadvantage of this approach.\n",
    "\n",
    "Advantage: Provides a robust estimate of the test error through dividng data into K Subsets and training model k times with each time using a different fold as the validation set and the remaining k-1 folds as the training set. Allows more accurate estimate of the test error since it considers all data points in the calculation \n",
    "\n",
    "Disadvantage: However, accurate, this can be expensive especially on large datasets.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A binary classifier has been fitted to a dataset and the following confusion matric has been calculated based on holdout (test) dataset. \n",
    " \n",
    " \n",
    " \n",
    " \n",
    "                        Predicted Class\n",
    "                 Positive            Negative\n",
    "ActualClass\n",
    "Positive            475                 116\n",
    "\n",
    "Negative            93                  841\n",
    "\n",
    "Based on this confusion matrix, calculate the following metrics:\n",
    "\n",
    "1. Accuracy: TP + TN) / (TP + TN + FP + FN)-> (475 + 841) / (475 + 116 + 93 + 841) = 1316 / 1625 = 0.8109\n",
    "\n",
    "11. Precision: TP/ (TP +FP) -> 475 / (475 + 116) = 0.8043\n",
    "\n",
    "iii. Sensitivity: TP/ (TP +FN) -> 475 / (475 + 93) = 0.8373\n",
    "\n",
    "iv. Specificity: TN/(FP+TN) -> 841 / (93 + 841) = 0.9013\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Two "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\tThe data set MotorcycleData2 has the following predictor variables:\n",
    "\n",
    "Age, gender, zone (i.e., geographic territory), engine.class, car.age, bonus.class (experience rating class reflecting history of accidents), policy.duration, CreditScore (the policyholderâ€™s insurance company assigned credit score). It has the following possible dependent variables: claims (number of claims for the policy), losses (total losses for the policy), and Claim Indicator (a binary variable indicating whether the policy has had at least one claim).\n",
    "\n",
    "a)\tProduce descriptive statistics of losses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyreadr\n",
      "  Downloading pyreadr-0.4.7-cp39-cp39-win_amd64.whl (1.1 MB)\n",
      "     ---------------------------------------- 1.1/1.1 MB 11.5 kB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas>=1.2.0 in c:\\users\\getrude\\anaconda3\\lib\\site-packages (from pyreadr) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\getrude\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyreadr) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\getrude\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyreadr) (1.21.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\getrude\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->pyreadr) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\getrude\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=1.2.0->pyreadr) (1.16.0)\n",
      "Installing collected packages: pyreadr\n",
      "Successfully installed pyreadr-0.4.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyreadr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyreadr\n",
    "\n",
    "result = pyreadr.read_r('MotorcycleData2.rda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = result['MotorcycleData2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     20000.000000\n",
      "mean       1357.432900\n",
      "std       10883.850339\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           0.000000\n",
      "75%           0.000000\n",
      "max      365347.000000\n",
      "Name: losses, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "losses_summary = df[\"losses\"].describe()\n",
    "print(losses_summary)\n",
    "#Descriptive statistics of losses \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b)\tWhat proportion of policy holders in the data have a claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Claim Indicator\"] = 0\n",
    "num_claims = sum(df[\"Claim Indicator\"] == 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of policy holders with a claim:0.000\n"
     ]
    }
   ],
   "source": [
    "df = result['MotorcycleData2']\n",
    "\n",
    "# Count the number of observations with a positive value in the \"Claim Indicator\" variable\n",
    "num_claims = sum(df[\"Claim Indicator\"] == 1)\n",
    "\n",
    "# Calculate the proportion of policy holders with a claim\n",
    "proportion_claims = num_claims / df.shape[0]\n",
    "\n",
    "print(\"Proportion of policy holders with a claim:{:.3f}\".format(proportion_claims))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c)\tUsing the random seed of 2, create a training and test sample, using 50% of the data for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations in training data: 10000\n",
      "Number of observations in test data: 10000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "df = result['MotorcycleData2']\n",
    "\n",
    "# Split the data set into training and test samples\n",
    "train, test = train_test_split(df, test_size=0.5, random_state=2)\n",
    "\n",
    "print(\"Number of observations in training data:\", len(train))\n",
    "print(\"Number of observations in test data:\", len(test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d)\tSing the training sample, fit a tree to the dependent variable claims using the predictor variables, but excluding the other dependent variables. Set the minimum deviance parameter to 0.005 using mindev = 0.005 in your tree function. Print output from tree fit. (5 points)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e9736419c14737ed357865f38d77d5a93ba72d994c9a24ccbb6ce36bc93e2e56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
